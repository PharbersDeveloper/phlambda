version: 0.0.0
framework: pyspark
engine: spark
language: python
language_version: 3.8.9
code:
  phjob:
    inputs: ~
    join_args: ~
    code: |
      from pyspark.sql.functions import *
      from pyspark.sql import *
      df_list = []

      def get_df(ds_name):
          return list(filter(lambda item: item["name"] == ds_name, df_list))[0]

      def pre_filter(args):
          ds_name = args["ds"]
          df_map = get_df(ds_name)
          df = df_map["df"]
          preFilter = args["preFilter"]
          enabled = preFilter["enabled"]
          distinct = preFilter["distinct"]
          expression = preFilter["expr"]
          if distinct:
              df = df.distinct()
          if enabled:
              if expression != "":
                  df = df.filter(expression)
          df_map["df"] = df

      def rename_df_cols(args):
          ds_name = args["ds"]
          df_map = get_df(ds_name)
          df = df_map["df"]
          df_map["df"] = df.selectExpr(list(map(lambda item: item["value"], args["columns"])))

      def pre_join_computed_columns(args):
          if len(args) > 0:
              ds_name = args["ds"]
              df_map = get_df(ds_name)
              df = df_map["df"]
              computedColumns = args["computedColumns"]
              for item in computedColumns:
                  df = df.selectExpr('*', f"{item['expr']} AS `{item['name']}`").withColumn(item["name"], col(item["name"]).cast(item["type"]))
              df_map["df"] = df

      def select_columns(args):
          ds_name = args["ds"]
          prefix = args["prefix"]
          df_map = get_df(ds_name)
          df_cols = list(map(lambda item: item[0], df_map["df"].dtypes))
          
          # 变换Col为不重复的列名 为后续select做准备
          def prefix_append(cols, falg):
              return list(map(lambda item: {"key": f"`{item}`", "value": f"`{item}` AS `{prefix}_{ds_name}_{item}`", "selected": falg, "prefix": prefix, "ds": ds_name}, cols))

          if args["type"] == "select":
              columns = args["columns"]
              diff_cols = prefix_append(list(set(df_cols) - set(columns)), False)
              select_cols = prefix_append(columns, True)
              all_cols = select_cols + diff_cols
          else:
              all_cols = prefix_append(df_cols, True)

          return {
              "ds": ds_name,
              "columns": all_cols
          }

      def post_join_computed_columns(df, args):
          if len(args) > 0:
              for item in args:
                  df = df.selectExpr('*', f"{item['expr']} AS `{item['name']}`").withColumn(item["name"], col(item["name"]).cast(item["type"]))
          return df

      def post_filter(df, args):
          distinct = args["distinct"]
          enabled = args["enabled"]
          expression = args["expr"]
          if distinct:
              df = df.distinct()
          if enabled and len(expression) > 0:
              df = df.filter(expression)
          return df

      def joins(select_cols ,args):
          on_func = {
              "=": "==",
              "AND": "&",
              "OR": "|"
          }
          def col_rename_handle(ds_name):
              return list(map(lambda col: col["value"], list(filter(lambda item: item["ds"] == ds_name, select_cols))[0]["columns"]))

          def col_on_handle(ds_name, col):
              columns = list(filter(lambda item: item["ds"] == ds_name, select_cols))[0]["columns"]
              return list(filter(lambda item: item["key"] == f"`{col}`", columns))[0]["value"].split(" ")[-1]

          def concat_select_df(ds_name):
              return f"""get_df("{ds_name}")["df"]"""

          def concat_on_cond(on_cond):
              def concat_exec(item):
                  return f"""get_df("{item["ds"]}")["df"]["{col_on_handle(item["ds"], item["column"])}"]"""
              cond = f" {on_func[on_cond['type']]} ".join(list(map(concat_exec, on_cond["conditions"])))
              return f"({cond})"

          ds_is_used = set()

          if args:
              first_join = args.pop(0) # args[0]
              join_str = ""
              if first_join["type"].lower() == "cross":
                  join_str = f"""{concat_select_df(first_join["datasets"][0]["name"])}.crossJoin({concat_select_df(first_join["datasets"][1]["name"])})"""
              else:
                  join_str = f"""{concat_select_df(first_join["datasets"][0]["name"])}.join({concat_select_df(first_join["datasets"][1]["name"])}, [{f"{on_func[first_join.get('coditionsMode', 'AND')]}".join(list(map(concat_on_cond, first_join["on"])))}], "{first_join["type"]}")"""
              ds_is_used.add(first_join["datasets"][0]["name"])
              ds_is_used.add(first_join["datasets"][1]["name"])
              for item in args:
                  ds_name = list(set(map(lambda ds: ds["name"], item["datasets"])) - ds_is_used)
                  for ds in ds_name:
                      if item["type"].lower() == "cross":
                          join_str += f""".crossJoin({concat_select_df(ds)})"""
                      else:
                          join_str += f""".join({concat_select_df(ds)}, [{f"{on_func[item.get('coditionsMode', 'AND')]}".join(list(map(concat_on_cond, item["on"])))}], "{item["type"]}")"""
              return eval(join_str)
          else:
              return None


      def execute(**kwargs):
          inputs = $inputs

          for ds_name in inputs:
              df_list.append({"name": ds_name, "df": kwargs["df_" + ds_name]})

          join_args = $join_args

          preFilters = join_args["preFilters"]
          preJoinComputedColumns = join_args["preJoinComputedColumns"]
          joinArgs = join_args["joins"]
          selectedColumns = join_args["selectedColumns"]
          postJoinComputedColumns = join_args["postJoinComputedColumns"]
          postFilter = join_args["postFilter"]

          for item in preFilters:
              pre_filter(item)

          for item in preJoinComputedColumns:
              pre_join_computed_columns(item)

          select_column_results = list(map(select_columns, selectedColumns))

          for item in select_column_results:
              rename_df_cols(item)

          df = joins(select_column_results, joinArgs)
          
          # 将重名的col 再次转为原有值（有前缀的添加前缀）
          selected_cols = []
          def rollback_col(item):
              current_col_name = item["value"].split(" ")[-1]
              current_prefix = f"""{item["prefix"]}_{item["ds"]}_"""
              original_col_name = item["value"].split(" ")[-1][len("`"+current_prefix):]
              if len(item["prefix"]) > 0 and item["prefix"] != " ":
                 return f"""{current_col_name} AS `{item["prefix"]}_{original_col_name}"""
              else:
                 return f"""{current_col_name} AS `{original_col_name}"""
    
          for item in select_column_results:
              selected_cols += list(map(rollback_col, list(filter(lambda col: col["selected"] == True, item["columns"]))))
          
          df = df.selectExpr(selected_cols)

          df = post_filter(post_join_computed_columns(df, postJoinComputedColumns), postFilter)

          return {"out_df": df}

